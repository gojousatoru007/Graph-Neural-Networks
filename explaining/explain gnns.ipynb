{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UFMEqofgYYkP"
   },
   "source": [
    "## Explaining Graph Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "7p6kg2ZQhzJx"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2987370221.py, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[1], line 9\u001b[1;36m\u001b[0m\n\u001b[1;33m    torch.backends.cudnn.benchmark = Falseimport torch\u001b[0m\n\u001b[1;37m                                                 ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "!pip install -q torch-scatter~=2.1.0 torch-sparse~=0.6.16 torch-cluster~=1.6.0 torch-spline-conv~=1.2.1 torch-geometric~=2.0.4 -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install -q captum==0.6.0\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = Falseimport torch\n",
    "!pip install -q torch-scatter~=2.1.0 torch-sparse~=0.6.16 torch-cluster~=1.6.0 torch-spline-conv~=1.2.1 torch-geometric~=2.0.4 -f https://data.pyg.org/whl/torch-{torch.__version__}.html\n",
    "!pip install -q captum==0.6.0\n",
    "\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.cuda.manual_seed_all(0)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "URim4zgS48p7"
   },
   "source": [
    "## GNNExplainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0KPp_MkFlKeJ",
    "outputId": "223667ff-e8ff-412c-81fc-15fd5268b48a"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.nn import Linear, Sequential, BatchNorm1d, ReLU, Dropout\n",
    "\n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric.nn import GINConv, global_add_pool, GNNExplainer\n",
    "\n",
    "dataset = TUDataset(root='data/TUDataset', name='MUTAG').shuffle()\n",
    "\n",
    "# Create training, validation, and test sets\n",
    "train_dataset = dataset[:int(len(dataset)*0.8)]\n",
    "val_dataset   = dataset[int(len(dataset)*0.8):int(len(dataset)*0.9)]\n",
    "test_dataset  = dataset[int(len(dataset)*0.9):]\n",
    "\n",
    "# Create mini-batches\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader   = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "class GIN(torch.nn.Module):\n",
    "    \"\"\"GIN\"\"\"\n",
    "    def __init__(self, dim_h):\n",
    "        super(GIN, self).__init__()\n",
    "        self.conv1 = GINConv(\n",
    "            Sequential(Linear(dataset.num_node_features, dim_h),\n",
    "                       BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv2 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.conv3 = GINConv(\n",
    "            Sequential(Linear(dim_h, dim_h), BatchNorm1d(dim_h), ReLU(),\n",
    "                       Linear(dim_h, dim_h), ReLU()))\n",
    "        self.lin1 = Linear(dim_h*3, dim_h*3)\n",
    "        self.lin2 = Linear(dim_h*3, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        h1 = self.conv1(x, edge_index)\n",
    "        h2 = self.conv2(h1, edge_index)\n",
    "        h3 = self.conv3(h2, edge_index)\n",
    "\n",
    "        h1 = global_add_pool(h1, batch)\n",
    "        h2 = global_add_pool(h2, batch)\n",
    "        h3 = global_add_pool(h3, batch)\n",
    "\n",
    "        h = torch.cat((h1, h2, h3), dim=1)\n",
    "\n",
    "        h = self.lin1(h)\n",
    "        h = h.relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.lin2(h)\n",
    "        \n",
    "        return F.log_softmax(h, dim=1)\n",
    "\n",
    "model = GIN(dim_h=32)\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, loader):\n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    model.eval()\n",
    "    loss = 0\n",
    "    acc = 0\n",
    "\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss += criterion(out, data.y) / len(loader)\n",
    "        acc += accuracy(out.argmax(dim=1), data.y) / len(loader)\n",
    "\n",
    "    return loss, acc\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "epochs = 200\n",
    "\n",
    "model.train()\n",
    "for epoch in range(epochs+1):\n",
    "    total_loss = 0\n",
    "    acc = 0\n",
    "    val_loss = 0\n",
    "    val_acc = 0\n",
    "\n",
    "    # Train on batches\n",
    "    for data in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        loss = criterion(out, data.y)\n",
    "        total_loss += loss / len(train_loader)\n",
    "        acc += accuracy(out.argmax(dim=1), data.y) / len(train_loader)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation\n",
    "        val_loss, val_acc = test(model, val_loader)\n",
    "\n",
    "    # Print metrics every 20 epochs\n",
    "    if(epoch % 20 == 0):\n",
    "        print(f'Epoch {epoch:>3} | Train Loss: {total_loss:.2f} | Train Acc: {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "test_loss, test_acc = test(model, test_loader)\n",
    "print(f'Test Loss: {test_loss:.2f} | Test Acc: {test_acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PAaa5q0yrmHA",
    "outputId": "147eeaca-24bb-4772-dd36-00aea751df07"
   },
   "outputs": [],
   "source": [
    "explainer = GNNExplainer(model, epochs=100, num_hops=1)\n",
    "data = dataset[-1]\n",
    "feature_mask, edge_mask = explainer.explain_graph(data.x, data.edge_index)\n",
    "feature_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "xPlAlqubQuha",
    "outputId": "75e3156d-3319-4264-c981-be49a927caa4"
   },
   "outputs": [],
   "source": [
    "fig = plt.figure(dpi=200)\n",
    "ax, G = explainer.visualize_subgraph(-1, data.edge_index, edge_mask, y=data.y)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lPvDumRKXlH9"
   },
   "source": [
    "## Explaining GNNs with Captum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f7-uY73-hpKi",
    "outputId": "23769a95-318b-42c4-ce81-43d5e84fd738"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(0)\n",
    "import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "from captum.attr import IntegratedGradients\n",
    "\n",
    "import torch_geometric.transforms as T\n",
    "from torch_geometric.datasets import Twitch\n",
    "from torch_geometric.nn import Explainer, GCNConv, to_captum\n",
    "\n",
    "\n",
    "dataset = Twitch('.', name=\"EN\")\n",
    "data = dataset[0]\n",
    "\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self, dim_h):\n",
    "        super().__init__()\n",
    "        self.conv1 = GCNConv(dataset.num_features, dim_h)\n",
    "        self.conv2 = GCNConv(dim_h, dataset.num_classes)\n",
    "\n",
    "    def forward(self, x, edge_index):\n",
    "        h = self.conv1(x, edge_index).relu()\n",
    "        h = F.dropout(h, p=0.5, training=self.training)\n",
    "        h = self.conv2(h, edge_index)\n",
    "        return F.log_softmax(h, dim=1)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = GCN(64).to(device)\n",
    "data = data.to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=5e-4)\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    log_logits = model(data.x, data.edge_index)\n",
    "    loss = F.nll_loss(log_logits, data.y)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "def accuracy(pred_y, y):\n",
    "    return ((pred_y == y).sum() / len(y)).item()\n",
    "\n",
    "@torch.no_grad()\n",
    "def test(model, data):\n",
    "    model.eval()\n",
    "    out = model(data.x, data.edge_index)\n",
    "    acc = accuracy(out.argmax(dim=1), data.y)\n",
    "    return acc\n",
    "  \n",
    "acc = test(model, data)\n",
    "print(f'Accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "EI8m7JERQ5LA",
    "outputId": "4a4f53a5-9c6f-49cd-efc3-8e50bfe90dfb"
   },
   "outputs": [],
   "source": [
    "node_idx = 0\n",
    "captum_model = to_captum(model, mask_type='node_and_edge', output_idx=node_idx)\n",
    "ig = IntegratedGradients(captum_model)\n",
    "edge_mask = torch.ones(data.num_edges, requires_grad=True, device=device)\n",
    "\n",
    "attr_node, attr_edge = ig.attribute(\n",
    "    (data.x.unsqueeze(0), edge_mask.unsqueeze(0)),\n",
    "    target=int(data.y[node_idx]),\n",
    "    additional_forward_args=(data.edge_index),\n",
    "    internal_batch_size=1)\n",
    "\n",
    "attr_node = attr_node.squeeze(0).abs().sum(dim=1)\n",
    "attr_node /= attr_node.max()\n",
    "attr_edge = attr_edge.squeeze(0).abs()\n",
    "attr_edge /= attr_edge.max()\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "explainer = Explainer(model)\n",
    "ax, G = explainer.visualize_subgraph(node_idx, data.edge_index, attr_edge, node_alpha=attr_node, y=data.y)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 661
    },
    "id": "R6XMAmNuRHnj",
    "outputId": "0b6ef69b-949c-4d9b-aba1-6e571543da7c"
   },
   "outputs": [],
   "source": [
    "node_idx = 101\n",
    "captum_model = to_captum(model, mask_type='node_and_edge', output_idx=node_idx)\n",
    "ig = IntegratedGradients(captum_model)\n",
    "edge_mask = torch.ones(data.num_edges, requires_grad=True, device=device)\n",
    "\n",
    "attr_node, attr_edge = ig.attribute(\n",
    "    (data.x.unsqueeze(0), edge_mask.unsqueeze(0)),\n",
    "    target=int(data.y[node_idx]),\n",
    "    additional_forward_args=(data.edge_index),\n",
    "    internal_batch_size=1)\n",
    "\n",
    "attr_node = attr_node.squeeze(0).abs().sum(dim=1)\n",
    "attr_node /= attr_node.max()\n",
    "attr_edge = attr_edge.squeeze(0).abs()\n",
    "attr_edge /= attr_edge.max()\n",
    "\n",
    "fig = plt.figure(dpi=200)\n",
    "explainer = Explainer(model)\n",
    "ax, G = explainer.visualize_subgraph(node_idx, data.edge_index, attr_edge, node_alpha=attr_node, y=data.y)\n",
    "ax.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7fa0016a911d70e86532c5706c9b4690ef8aee26a1d06018a1e37e463667ff8c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
