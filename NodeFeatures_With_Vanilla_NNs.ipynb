{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ed4b87a-e68c-4c74-83ce-9f5bcfe33b35",
   "metadata": {},
   "source": [
    "# Including Node Features with Neural Networks\n",
    "\n",
    "- So far, we've just used Graph Topology.\n",
    "- Graph Datasets tend to be richer than a mere set of connections: nodes and edges can also have features to represent scores, colors, words, and so on.\n",
    "- Including This Additional Info in our input data is essential to produce the best embeddings possible.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9e6748d-da02-4045-9ea5-1edfaf21545d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "torch.manual_seed(0)\n",
    "\n",
    "torch.cuda.manual_seed(0)\n",
    "\n",
    "torch.cuda.manual_seed_all(0)\n",
    "\n",
    "torch.backends.cudnn.deterministic = True\n",
    "\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de3415ab-8909-4bc8-b641-8b6e068ef50a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: Cora()\n",
      "---------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 2708\n",
      "Number of features: 1433\n",
      "Number of classes: 7\n",
      "\n",
      "Graph:\n",
      "------\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: False\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import Planetoid\n",
    "\n",
    "dataset = Planetoid(root = '.', name = \"Cora\")\n",
    "\n",
    "data = dataset[0]\n",
    "\n",
    "# Print information about the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('---------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Print information about the graph\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a2017a4-3786-4c6e-9b9c-6e8f24500c3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: FacebookPagePage()\n",
      "-----------------------\n",
      "Number of graphs: 1\n",
      "Number of nodes: 22470\n",
      "Number of features: 128\n",
      "Number of classes: 4\n",
      "\n",
      "Graph:\n",
      "------\n",
      "Edges are directed: False\n",
      "Graph has isolated nodes: False\n",
      "Graph has loops: True\n"
     ]
    }
   ],
   "source": [
    "from torch_geometric.datasets import FacebookPagePage\n",
    "\n",
    "# Import dataset from PyTorch Geometric\n",
    "dataset = FacebookPagePage(root=\".\")\n",
    "\n",
    "data = dataset[0]\n",
    "\n",
    "# Print information about the dataset\n",
    "print(f'Dataset: {dataset}')\n",
    "print('-----------------------')\n",
    "print(f'Number of graphs: {len(dataset)}')\n",
    "print(f'Number of nodes: {data.x.shape[0]}')\n",
    "print(f'Number of features: {dataset.num_features}')\n",
    "print(f'Number of classes: {dataset.num_classes}')\n",
    "\n",
    "# Print information about the graph\n",
    "print(f'\\nGraph:')\n",
    "print('------')\n",
    "print(f'Edges are directed: {data.is_directed()}')\n",
    "print(f'Graph has isolated nodes: {data.has_isolated_nodes()}')\n",
    "print(f'Graph has loops: {data.has_self_loops()}')\n",
    "\n",
    "# Create masks\n",
    "data.train_mask = range(18000)\n",
    "data.val_mask = range(18001, 20000)\n",
    "data.test_mask = range(20001, 22470)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0361f6c-97f5-4c95-9f7e-26ed839fbc3c",
   "metadata": {},
   "source": [
    "# Cora Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "048662f0-72ea-405c-9c13-442f2cd8a5f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>1424</th>\n",
       "      <th>1425</th>\n",
       "      <th>1426</th>\n",
       "      <th>1427</th>\n",
       "      <th>1428</th>\n",
       "      <th>1429</th>\n",
       "      <th>1430</th>\n",
       "      <th>1431</th>\n",
       "      <th>1432</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2704</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2705</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2706</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2707</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2708 rows Ã— 1434 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0    1    2    3    4    5    6    7    8    9  ...  1424  1425  1426  \\\n",
       "0     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "1     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "3     0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "4     0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "...   ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   ...   ...   ...   \n",
       "2703  0.0  0.0  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...   0.0   1.0   0.0   \n",
       "2704  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2705  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2706  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "2707  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   0.0   0.0   0.0   \n",
       "\n",
       "      1427  1428  1429  1430  1431  1432  label  \n",
       "0      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "1      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "2      0.0   0.0   0.0   0.0   0.0   0.0      4  \n",
       "3      0.0   0.0   0.0   0.0   0.0   0.0      0  \n",
       "4      0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "...    ...   ...   ...   ...   ...   ...    ...  \n",
       "2703   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2704   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2705   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2706   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "2707   0.0   0.0   0.0   0.0   0.0   0.0      3  \n",
       "\n",
       "[2708 rows x 1434 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "dataset = Planetoid(root=\".\", name=\"Cora\")\n",
    "data = dataset[0]\n",
    "\n",
    "df_x = pd.DataFrame(data.x.numpy())\n",
    "df_x['label'] = pd.DataFrame(data.y)\n",
    "df_x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f4c53375-ffdd-418d-8531-08e9fde5273f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=1433, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=7, bias=True)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.959 | Train Acc: 14.29% | Val Loss: 2.00 | Val Acc: 12.40%\n",
      "Epoch  20 | Train Loss: 0.110 | Train Acc: 100.00% | Val Loss: 1.46 | Val Acc: 49.40%\n",
      "Epoch  40 | Train Loss: 0.014 | Train Acc: 100.00% | Val Loss: 1.44 | Val Acc: 51.00%\n",
      "Epoch  60 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.40 | Val Acc: 53.80%\n",
      "Epoch  80 | Train Loss: 0.008 | Train Acc: 100.00% | Val Loss: 1.37 | Val Acc: 55.40%\n",
      "Epoch 100 | Train Loss: 0.009 | Train Acc: 100.00% | Val Loss: 1.34 | Val Acc: 54.60%\n",
      "\n",
      "MLP test accuracy: 53.40%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(0)\n",
    "from torch.nn import Linear\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def accuracy(y_pred, y_true):\n",
    "    \"\"\"Calculate accuracy.\"\"\"\n",
    "    return torch.sum(y_pred == y_true) / len(y_true) # can also use area under ROC \n",
    "\n",
    "\n",
    "class MLP(torch.nn.Module):\n",
    "    \"\"\"Multilayer Perceptron\"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.linear1 = Linear(dim_in, dim_h)\n",
    "        self.linear2 = Linear(dim_h, dim_out)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.linear1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.linear2(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss() \n",
    "        optimizer = torch.optim.Adam(self.parameters(),\n",
    "                                          lr=0.01,\n",
    "                                          weight_decay=5e-4)\n",
    "\n",
    "        self.train()\n",
    "        for epoch in range(epochs+1): # mini-batches\n",
    "            optimizer.zero_grad() # setting gradients = value to 0 initially\n",
    "            out = self(data.x)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
    "                          data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if(epoch % 20 == 0):\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
    "                                  data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
    "                      f' {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                      f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    @torch.no_grad() # torch module should not consider the grad calculate computation graph passses       \n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc\n",
    "\n",
    "# Create MLP model\n",
    "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
    "print(mlp)\n",
    "\n",
    "# Train\n",
    "mlp.fit(data, epochs=100)\n",
    "\n",
    "# Test\n",
    "acc = mlp.test(data)\n",
    "print(f'\\nMLP test accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99d6b189-420a-4b65-bca8-e823c62a1019",
   "metadata": {},
   "source": [
    "## Classifying Nodes with Vanilla GNN\n",
    "\n",
    "$ h = x W^T $\n",
    "\n",
    "$ h = sum xi Wt$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0f23358d-d62d-46b7-bd6c-97ef76d00691",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VanillaGNNLayer(torch.nn.Module): # sub-class of torch.nn.Module\n",
    "    def __init__(self, dim_in, dim_out): # dim_in and dim_out as input\n",
    "        super().__init__()\n",
    "        self.linear = Linear(dim_in, dim_out, bias=False)\n",
    "\n",
    "    def forward(self, x, adjacency):\n",
    "        x = self.linear(x) # linear transformation # making it a linear vector\n",
    "        x = torch.sparse.mm(adjacency, x) # multiplication with adjacency matrix\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2b45cc79-12b6-4763-97d9-fe659bce5251",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 1., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch_geometric.utils import to_dense_adj\n",
    "\n",
    "adjacency = to_dense_adj(data.edge_index)[0] # converting edge index in coordinate format to a dense adjacency matrix\n",
    "adjacency += torch.eye(len(adjacency)) # A tilda = A + I \n",
    "adjacency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdd2bd93-5147-4f33-a364-59f7a2573f7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=1433, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=7, bias=False)\n",
      "  )\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.991 | Train Acc: 15.71% | Val Loss: 2.11 | Val Acc: 9.40%\n",
      "Epoch  20 | Train Loss: 0.065 | Train Acc: 99.29% | Val Loss: 1.47 | Val Acc: 76.80%\n",
      "Epoch  40 | Train Loss: 0.014 | Train Acc: 100.00% | Val Loss: 2.11 | Val Acc: 75.40%\n",
      "Epoch  60 | Train Loss: 0.007 | Train Acc: 100.00% | Val Loss: 2.22 | Val Acc: 75.40%\n",
      "Epoch  80 | Train Loss: 0.004 | Train Acc: 100.00% | Val Loss: 2.20 | Val Acc: 76.80%\n",
      "Epoch 100 | Train Loss: 0.003 | Train Acc: 100.00% | Val Loss: 2.19 | Val Acc: 77.00%\n",
      "\n",
      "GNN test accuracy: 76.60%\n"
     ]
    }
   ],
   "source": [
    "class VanillaGNN(torch.nn.Module):\n",
    "    \"\"\"Vanilla Graph Neural Network\"\"\"\n",
    "    def __init__(self, dim_in, dim_h, dim_out):\n",
    "        super().__init__()\n",
    "        self.gnn1 = VanillaGNNLayer(dim_in, dim_h) # using our layer early defined we have one hidden layer \n",
    "        self.gnn2 = VanillaGNNLayer(dim_h, dim_out) # hidden -> out\n",
    "\n",
    "    def forward(self, x, adjacency): # forward propagation\n",
    "        h = self.gnn1(x, adjacency) # this is the transformation from layer 1\n",
    "        h = torch.relu(h) # we apply relu function on h -> sigma(z(i))\n",
    "        h = self.gnn2(h, adjacency) # then applying layer 2 on it\n",
    "        return F.log_softmax(h, dim=1) # softmaxing to the output with dimension 1\n",
    "\n",
    "    def fit(self, data, epochs):\n",
    "        criterion = torch.nn.CrossEntropyLoss() # fitting the data, we first have our J\n",
    "        optimizer = torch.optim.Adam(self.parameters(), # adam optimizer to find best param\n",
    "                                      lr=0.01,\n",
    "                                      weight_decay=5e-4)\n",
    "\n",
    "        self.train() # training\n",
    "        for epoch in range(epochs+1):\n",
    "            optimizer.zero_grad() # inititalize all gradients as 0\n",
    "            out = self(data.x, adjacency)\n",
    "            loss = criterion(out[data.train_mask], data.y[data.train_mask])\n",
    "            acc = accuracy(out[data.train_mask].argmax(dim=1),\n",
    "                          data.y[data.train_mask])\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if(epoch % 20 == 0):\n",
    "                val_loss = criterion(out[data.val_mask], data.y[data.val_mask])\n",
    "                val_acc = accuracy(out[data.val_mask].argmax(dim=1),\n",
    "                                  data.y[data.val_mask])\n",
    "                print(f'Epoch {epoch:>3} | Train Loss: {loss:.3f} | Train Acc:'\n",
    "                      f' {acc*100:>5.2f}% | Val Loss: {val_loss:.2f} | '\n",
    "                      f'Val Acc: {val_acc*100:.2f}%')\n",
    "\n",
    "    @torch.no_grad() # \n",
    "    def test(self, data):\n",
    "        self.eval()\n",
    "        out = self(data.x, adjacency)\n",
    "        acc = accuracy(out.argmax(dim=1)[data.test_mask], data.y[data.test_mask])\n",
    "        return acc\n",
    "\n",
    "# Create the Vanilla GNN model\n",
    "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
    "print(gnn)\n",
    "\n",
    "# Train\n",
    "gnn.fit(data, epochs=100)\n",
    "\n",
    "# Test\n",
    "acc = gnn.test(data)\n",
    "print(f'\\nGNN test accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4e9531c-c753-4dc7-bf4d-7a4d1769dfe0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cd50bb9-9d46-470d-89e1-0eac2737f7d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d699bdc-326c-487e-837f-5cd150541f7b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ec4d0e1-9ae5-41fb-8d2d-6f6048d7fa85",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5e11ca-d193-435c-aaf0-3ec58d27716a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c1e389-d19c-4e94-8be7-97a9c24e99a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b93133-9a5c-4e85-a4f9-45df90f6ac78",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "484494ea-0ef2-481c-b41b-9e622f24ba56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "61913fa9-8791-4c77-9b26-0d5350112a3f",
   "metadata": {},
   "source": [
    "# Facebook Page-Page Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4607b1ac-6475-4556-8e5a-90e33e9065f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP(\n",
      "  (linear1): Linear(in_features=128, out_features=16, bias=True)\n",
      "  (linear2): Linear(in_features=16, out_features=4, bias=True)\n",
      ")\n",
      "Epoch   0 | Train Loss: 1.401 | Train Acc: 28.11% | Val Loss: 1.40 | Val Acc: 28.91%\n",
      "Epoch  20 | Train Loss: 0.671 | Train Acc: 73.47% | Val Loss: 0.68 | Val Acc: 72.94%\n",
      "Epoch  40 | Train Loss: 0.579 | Train Acc: 76.95% | Val Loss: 0.61 | Val Acc: 74.89%\n",
      "Epoch  60 | Train Loss: 0.549 | Train Acc: 78.20% | Val Loss: 0.60 | Val Acc: 75.59%\n",
      "Epoch  80 | Train Loss: 0.533 | Train Acc: 78.76% | Val Loss: 0.60 | Val Acc: 75.39%\n",
      "Epoch 100 | Train Loss: 0.520 | Train Acc: 79.23% | Val Loss: 0.60 | Val Acc: 75.39%\n",
      "\n",
      "MLP test accuracy: 75.33%\n",
      "\n",
      "VanillaGNN(\n",
      "  (gnn1): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=128, out_features=16, bias=False)\n",
      "  )\n",
      "  (gnn2): VanillaGNNLayer(\n",
      "    (linear): Linear(in_features=16, out_features=4, bias=False)\n",
      "  )\n",
      ")\n",
      "Epoch   0 | Train Loss: 176.683 | Train Acc: 28.31% | Val Loss: 173.10 | Val Acc: 28.41%\n",
      "Epoch  20 | Train Loss: 6.675 | Train Acc: 79.69% | Val Loss: 4.49 | Val Acc: 80.19%\n",
      "Epoch  40 | Train Loss: 2.284 | Train Acc: 82.15% | Val Loss: 1.60 | Val Acc: 83.64%\n",
      "Epoch  60 | Train Loss: 1.228 | Train Acc: 83.92% | Val Loss: 1.06 | Val Acc: 84.34%\n",
      "Epoch  80 | Train Loss: 1.021 | Train Acc: 84.69% | Val Loss: 0.93 | Val Acc: 84.59%\n",
      "Epoch 100 | Train Loss: 2.758 | Train Acc: 83.19% | Val Loss: 1.58 | Val Acc: 83.29%\n",
      "\n",
      "GNN test accuracy: 82.75%\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "dataset = FacebookPagePage(root=\".\")\n",
    "data = dataset[0]\n",
    "data.train_mask = range(18000)\n",
    "data.val_mask = range(18001, 20000)\n",
    "data.test_mask = range(20001, 22470)\n",
    "\n",
    "# Adjacency matrix\n",
    "adjacency = to_dense_adj(data.edge_index)[0]\n",
    "adjacency += torch.eye(len(adjacency))\n",
    "adjacency\n",
    "\n",
    "# MLP\n",
    "mlp = MLP(dataset.num_features, 16, dataset.num_classes)\n",
    "print(mlp)\n",
    "mlp.fit(data, epochs=100)\n",
    "acc = mlp.test(data)\n",
    "print(f'\\nMLP test accuracy: {acc*100:.2f}%\\n')\n",
    "\n",
    "# GCN\n",
    "gnn = VanillaGNN(dataset.num_features, 16, dataset.num_classes)\n",
    "print(gnn)\n",
    "gnn.fit(data, epochs=100)\n",
    "acc = gnn.test(data)\n",
    "print(f'\\nGNN test accuracy: {acc*100:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e09d727-4f80-42f4-9457-53bddee39298",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
